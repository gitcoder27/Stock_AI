{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitcoder27/Stock_AI/blob/main/stock_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip cache purge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E58ugsc5Rhq2",
        "outputId": "a2576011-eeda-415d-e2e0-0e5a5431b206"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files removed: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y python3-dev zlib1g-dev libjpeg-dev cmake swig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukfWNz5XRp4G",
        "outputId": "0c38349c-3da4-4cba-889e-5244ac5498c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libjpeg-dev is already the newest version (8c-2ubuntu8).\n",
            "libjpeg-dev set to manually installed.\n",
            "python3-dev is already the newest version (3.8.2-0ubuntu2).\n",
            "python3-dev set to manually installed.\n",
            "cmake is already the newest version (3.16.3-1ubuntu1.20.04.1).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-2ubuntu1.5).\n",
            "zlib1g-dev set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 1,086 kB of archives.\n",
            "After this operation, 5,413 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 swig4.0 amd64 4.0.1-5build1 [1,081 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 swig all 4.0.1-5build1 [5,528 B]\n",
            "Fetched 1,086 kB in 1s (907 kB/s)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 128285 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.1-5build1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.1-5build1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.1-5build1_all.deb ...\n",
            "Unpacking swig (4.0.1-5build1) ...\n",
            "Setting up swig4.0 (4.0.1-5build1) ...\n",
            "Setting up swig (4.0.1-5build1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna pandas numpy ta stable_baselines3"
      ],
      "metadata": {
        "id": "MpmUuzXWJGnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89bda733-5c63-4299-9d40-30a9a6da2267"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.4.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.24.2)\n",
            "Collecting ta\n",
            "  Downloading ta-0.10.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-1.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.8/171.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (6.0)\n",
            "Collecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.4.47)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.65.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
            "Collecting importlib-metadata~=4.13\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from stable_baselines3) (2.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from stable_baselines3) (3.7.1)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.9/dist-packages (from stable_baselines3) (1.13.1+cu116)\n",
            "Collecting gym==0.21\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD7u9t9kIpXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "a8281451-780a-448c-99cf-f4fab524fd9f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0d6a26263be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_all_ta_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import optuna\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ta import add_all_ta_features\n",
        "import gym\n",
        "from gym import spaces\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "# Reduce the total_timesteps\n",
        "total_timesteps = 100000\n",
        "\n",
        "\n",
        "\n",
        "selected_features = [\"open\", \"high\", \"low\", \"close\", \"momentum_rsi\", \"momentum_rsi_9\" \"trend_macd\", \"momentum_stoch\", \"trend_supertrend\"]\n",
        "\n",
        "# Read the data\n",
        "def read_data(fileName):\n",
        "    df = pd.read_csv(fileName)\n",
        "\n",
        "    # Compute technical indicators\n",
        "    df = add_all_ta_features(df, open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=pd.DataFrame())\n",
        "\n",
        "    # Select desired features\n",
        "    \n",
        "    df = df[selected_features]\n",
        "\n",
        "    # Normalize the data\n",
        "    df_norm = (df - df.min()) / (df.max() - df.min())\n",
        "\n",
        "    return df_norm\n",
        "\n",
        "# Create the sliding window dataset\n",
        "def create_sliding_window(df_norm, lookback_window=60):\n",
        "    X, y = [], []\n",
        "    for i in range(lookback_window, len(df_norm)):\n",
        "        X.append(df_norm.iloc[i - lookback_window:i].values)\n",
        "        y.append(df_norm.iloc[i][\"close\"])\n",
        "\n",
        "    X = np.stack(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "df_norm = read_data(\"candle_data_train_copy.csv\")\n",
        "X, y = create_sliding_window(df_norm)\n",
        "\n",
        "# Creating the environment\n",
        "class StockTradingEnv(gym.Env):\n",
        "    def __init__(self, X, y, take_profit=60):\n",
        "        super(StockTradingEnv, self).__init__()\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.take_profit = take_profit\n",
        "\n",
        "        self.action_space = spaces.Discrete(3)  # Buy, Sell, Hold\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(60, len(selected_features)), dtype=np.float32)\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def step(self, action):\n",
        "        # Compute the next state based on the action and the current state\n",
        "        self.current_step += 1\n",
        "        state = self.X[self.current_step]\n",
        "        reward = self._get_reward(action)\n",
        "        done = self.current_step == len(self.X) - 1\n",
        "\n",
        "        return state, reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = 0\n",
        "        return self.X[self.current_step]\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        # Optional: Implement a rendering function if you want to visualize the environment\n",
        "        pass\n",
        "\n",
        "    def _get_reward(self, action):\n",
        "        # Compute the reward based on the action and the current state\n",
        "        current_price = self.y[self.current_step]\n",
        "        next_price = self.y[self.current_step + 1]\n",
        "        profit = (next_price - current_price) / current_price * 100\n",
        "\n",
        "        if action == 0:  # Buy\n",
        "            if profit >= self.take_profit:\n",
        "                return 1\n",
        "            else:\n",
        "                return -1\n",
        "        elif action == 1:  # Sell\n",
        "            if profit <= -self.take_profit:\n",
        "                return 1\n",
        "            else:\n",
        "                return -1\n",
        "        else:  # Hold\n",
        "            return 0\n",
        "\n",
        "env = StockTradingEnv(X, y)\n",
        "\n",
        "# implement PPO algo\n",
        "vec_env = DummyVecEnv([lambda: env])\n",
        "\n",
        "model = PPO(\"MlpPolicy\", vec_env, verbose=1)\n",
        "model.learn(total_timesteps=total_timesteps)\n",
        "\n",
        "# Evaluate the agent\n",
        "def evaluate_agent(model, env, num_episodes=10):\n",
        "    rewards = []\n",
        "    for _ in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        episode_reward = 0\n",
        "        while not done:\n",
        "            action, _states = model.predict(state)\n",
        "            state, reward, done, _ = env.step(action)\n",
        "            episode_reward += reward\n",
        "        rewards.append(episode_reward)\n",
        "    return np.mean(rewards)\n",
        "\n",
        "# Create a new environment for evaluation with new data (e.g., X_test, y_test)\n",
        "df_norm_test = read_data(\"candle_data_test_copy.csv\")\n",
        "X_test, y_test = create_sliding_window(df_norm_test)\n",
        "\n",
        "eval_env = StockTradingEnv(X_test, y_test)\n",
        "\n",
        "mean_reward = evaluate_agent(model, eval_env)\n",
        "print(\"Mean reward:\", mean_reward)\n",
        "\n",
        "# fine tune the model\n",
        "def objective(trial):\n",
        "    # Define hyperparameters for the PPO agent\n",
        "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)\n",
        "    gamma = trial.suggest_uniform(\"gamma\", 0.9, 1.0)\n",
        "    n_steps = trial.suggest_int(\"n_steps\", 16, 256)\n",
        "    ent_coef = trial.suggest_loguniform(\"ent_coef\", 1e-5, 1)\n",
        "    clip_range = trial.suggest_uniform(\"clip_range\", 0.1, 0.4)\n",
        "\n",
        "    env = StockTradingEnv(X, y)\n",
        "    vec_env = DummyVecEnv([lambda: env])\n",
        "\n",
        "    model = PPO(\"MlpPolicy\", vec_env, learning_rate=learning_rate, gamma=gamma, n_steps=n_steps, ent_coef=ent_coef, clip_range=clip_range, verbose=0)\n",
        "    model.learn(total_timesteps=total_timesteps)\n",
        "\n",
        "    return evaluate_agent(model, env)\n",
        "\n",
        "# Reduce the number of trials in Optuna\n",
        "n_trials_optuna = 25\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=n_trials_optuna)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "KnkWIwX0NJC3"
      }
    }
  ]
}